"""
è¯Šæ–­VAEé‡å»ºè¯¯å·®é—®é¢˜ - ä¸“æ³¨äºå½’ä¸€åŒ–å’Œç¼©æ”¾
"""

import torch
import sys
import os
from pathlib import Path
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent))

from vae_wrapper import VAEInterface

def diagnose_vae():
    """è¯Šæ–­VAEé‡å»ºé—®é¢˜"""
    print("=" * 60)
    print("VAEå½’ä¸€åŒ–è¯Šæ–­")
    print("=" * 60)
    
    # åˆ›å»ºVAEæ¥å£
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    vae_path = "/kaggle/input/kl-vae-best-pt/kl_vae_best.pt"
    if not os.path.exists(vae_path):
        vae_path = "domain_adaptive_diffusion/vae/kl_vae_best.pt"
    
    vae = VAEInterface(vae_path=vae_path, device=device)
    
    print(f"\nVAEé…ç½®:")
    print(f"  scale_factor: {vae.scale_factor}")
    print(f"  è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("vae_reconstruction_analysis")
    output_dir.mkdir(exist_ok=True)
    
    # æµ‹è¯•çœŸå®çš„å¾®å¤šæ™®å‹’å›¾åƒ
    print("\n1. æµ‹è¯•çœŸå®å¾®å¤šæ™®å‹’å›¾åƒ")
    test_real_microdoppler_images(vae, output_dir)
    
    # æµ‹è¯•æ›´å¤šçœŸå®å›¾åƒçš„ç»Ÿè®¡
    print("\n2. åˆ†æçœŸå®æ•°æ®é›†çš„é‡å»ºè´¨é‡")
    analyze_dataset_reconstruction(vae, output_dir)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼å¯¹æ¯”å›¾ä¿å­˜åœ¨ {output_dir} ç›®å½•")
        
def test_reconstruction(vae, image, name):
    """æµ‹è¯•å•ä¸ªå›¾åƒçš„é‡å»º"""
    print(f"  è¾“å…¥èŒƒå›´: [{image.min():.3f}, {image.max():.3f}]")
    
    # ç¼–ç 
    with torch.no_grad():
        latent = vae.encode_batch(image)
    print(f"  ç¼–ç latent: shape={latent.shape}, mean={latent.mean():.4f}, std={latent.std():.4f}")
    print(f"  ç¼–ç latentèŒƒå›´: [{latent.min():.3f}, {latent.max():.3f}]")
    
    # è§£ç 
    with torch.no_grad():
        recon = vae.decode_batch(latent)
    print(f"  é‡å»ºèŒƒå›´: [{recon.min():.3f}, {recon.max():.3f}]")
    
    # å°†ä¸¤è€…éƒ½clampåˆ°[0,1]æ¥è®¡ç®—è¯¯å·®
    image_clamped = torch.clamp(image, 0, 1)
    recon_clamped = torch.clamp(recon, 0, 1)
    
    # è®¡ç®—è¯¯å·®
    mse = ((image_clamped - recon_clamped) ** 2).mean().item()
    mae = (image_clamped - recon_clamped).abs().mean().item()
    
    print(f"  é‡å»ºè¯¯å·®: MSE={mse:.4f}, MAE={mae:.4f}")
    
    # åˆ†æè¯¯å·®åˆ†å¸ƒ
    error = (image_clamped - recon_clamped).abs()
    print(f"  è¯¯å·®åˆ†å¸ƒ: mean={error.mean():.4f}, max={error.max():.4f}")
    
def analyze_vae_internals(vae, test_img):
    """åˆ†æVAEå†…éƒ¨å¤„ç†ç»†èŠ‚"""
    print("\nåˆ†æVAEå†…éƒ¨å¤„ç†:")
    
    # ç›´æ¥è°ƒç”¨VAEçš„encodeæ–¹æ³•æŸ¥çœ‹ä¸­é—´ç»“æœ
    with torch.no_grad():
        # ç¼–ç 
        posterior = vae.vae.encode(test_img)
        z = posterior.sample()
        
        print(f"  åŸå§‹latent (æœªç¼©æ”¾): mean={z.mean():.4f}, std={z.std():.4f}")
        print(f"  åŸå§‹latentèŒƒå›´: [{z.min():.3f}, {z.max():.3f}]")
        
        # åº”ç”¨scale factor
        z_scaled = z * vae.scale_factor
        print(f"  ç¼©æ”¾ålatent: mean={z_scaled.mean():.4f}, std={z_scaled.std():.4f}")
        print(f"  ç¼©æ”¾åèŒƒå›´: [{z_scaled.min():.3f}, {z_scaled.max():.3f}]")
        
        # è§£ç 
        z_unscaled = z_scaled / vae.scale_factor
        decoded = vae.vae.decode(z_unscaled)
        
        print(f"  è§£ç è¾“å‡ºèŒƒå›´: [{decoded.min():.3f}, {decoded.max():.3f}]")
        
def test_reconstruction_with_save(vae, image, name, save_path):
    """æµ‹è¯•é‡å»ºå¹¶ä¿å­˜å¯¹æ¯”å›¾"""
    print(f"  è¾“å…¥èŒƒå›´: [{image.min():.3f}, {image.max():.3f}]")
    
    # ç¼–ç 
    with torch.no_grad():
        latent = vae.encode_batch(image)
    print(f"  ç¼–ç latent: shape={latent.shape}, mean={latent.mean():.4f}, std={latent.std():.4f}")
    
    # è§£ç 
    with torch.no_grad():
        recon = vae.decode_batch(latent)
    
    # è®¡ç®—è¯¯å·®
    image_clamped = torch.clamp(image, 0, 1)
    recon_clamped = torch.clamp(recon, 0, 1)
    mse = ((image_clamped - recon_clamped) ** 2).mean().item()
    mae = (image_clamped - recon_clamped).abs().mean().item()
    print(f"  é‡å»ºè¯¯å·®: MSE={mse:.4f}, MAE={mae:.4f}")
    
    # ä¿å­˜å¯¹æ¯”å›¾
    save_comparison_figure(image_clamped, recon_clamped, save_path, name, mse, mae)
    
    return recon_clamped

def save_comparison_figure(original, reconstructed, save_path, title, mse, mae):
    """ä¿å­˜å¯¹æ¯”å›¾"""
    # è½¬æ¢ä¸ºnumpyå¹¶ç§»åˆ°CPU
    orig_np = original[0].cpu().numpy().transpose(1, 2, 0)
    recon_np = reconstructed[0].cpu().numpy().transpose(1, 2, 0)
    diff_np = np.abs(orig_np - recon_np)
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))
    
    # åŸå§‹å›¾åƒ
    axes[0].imshow(orig_np)
    axes[0].set_title('åŸå§‹å›¾åƒ')
    axes[0].axis('off')
    
    # é‡å»ºå›¾åƒ
    axes[1].imshow(recon_np)
    axes[1].set_title('é‡å»ºå›¾åƒ')
    axes[1].axis('off')
    
    # å·®å¼‚å›¾
    im_diff = axes[2].imshow(diff_np, cmap='hot')
    axes[2].set_title('ç»å¯¹å·®å¼‚')
    axes[2].axis('off')
    plt.colorbar(im_diff, ax=axes[2], fraction=0.046)
    
    # å·®å¼‚ç›´æ–¹å›¾
    axes[3].hist(diff_np.flatten(), bins=50, edgecolor='black')
    axes[3].set_title(f'å·®å¼‚åˆ†å¸ƒ\nMSE={mse:.4f}, MAE={mae:.4f}')
    axes[3].set_xlabel('ç»å¯¹å·®å¼‚')
    axes[3].set_ylabel('åƒç´ æ•°')
    
    plt.suptitle(f'{title} - VAEé‡å»ºè´¨é‡åˆ†æ', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")

def test_real_microdoppler_images(vae, output_dir):
    """æµ‹è¯•çœŸå®å¾®å¤šæ™®å‹’å›¾åƒ"""
    
    # æŸ¥æ‰¾æ•°æ®é›†ç›®å½•
    dataset_dirs = [
        Path("dataset/organized_gait_dataset"),
        Path("/kaggle/input/organized-gait-dataset"),
        Path("G:/VA-VAE/dataset/organized_gait_dataset")
    ]
    
    dataset_dir = None
    for d in dataset_dirs:
        if d.exists():
            dataset_dir = d
            break
    
    if dataset_dir is None:
        print("  æœªæ‰¾åˆ°æ•°æ®é›†ç›®å½•ï¼Œè·³è¿‡çœŸå®å›¾åƒæµ‹è¯•")
        return
    
    # è·å–ä¸€äº›ç¤ºä¾‹å›¾åƒ
    subdirs = ["Normal_free", "Normal_line", "Bag_free", "Backpack_free"]
    test_images = []
    
    for subdir in subdirs:
        subdir_path = dataset_dir / subdir
        if subdir_path.exists():
            # è·å–ç¬¬ä¸€ä¸ªç”¨æˆ·çš„ç¬¬ä¸€å¼ å›¾åƒ
            user_dirs = sorted([d for d in subdir_path.iterdir() if d.is_dir()])
            if user_dirs:
                images = list(user_dirs[0].glob("*.jpg"))[:1]
                if images:
                    test_images.append((images[0], subdir))
    
    if not test_images:
        print("  æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
        return
    
    # æµ‹è¯•æ¯å¼ å›¾åƒ
    for img_path, gait_type in test_images:
        print(f"\n  æµ‹è¯• {gait_type} - {img_path.name}")
        
        # åŠ è½½å›¾åƒ
        pil_img = Image.open(img_path).convert("RGB")
        
        # è°ƒæ•´åˆ°256x256
        pil_img = pil_img.resize((256, 256), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–åˆ°[0, 1]
        img_array = np.array(pil_img).astype(np.float32) / 255.0
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0).to(vae.device)
        
        # æµ‹è¯•é‡å»º
        save_path = output_dir / f"real_{gait_type}.png"
        test_reconstruction_with_save(vae, img_tensor, f"çœŸå®å›¾åƒ-{gait_type}", save_path)

def analyze_dataset_reconstruction(vae, output_dir):
    """åˆ†ææ•´ä¸ªæ•°æ®é›†çš„é‡å»ºè´¨é‡"""
    
    # æŸ¥æ‰¾æ•°æ®é›†ç›®å½•
    dataset_dirs = [
        Path("dataset/organized_gait_dataset"),
        Path("/kaggle/input/organized-gait-dataset"),
        Path("G:/VA-VAE/dataset/organized_gait_dataset")
    ]
    
    dataset_dir = None
    for d in dataset_dirs:
        if d.exists():
            dataset_dir = d
            break
    
    if dataset_dir is None:
        print("  æœªæ‰¾åˆ°æ•°æ®é›†ç›®å½•")
        return
    
    # ç»Ÿè®¡æ‰€æœ‰æ­¥æ€ç±»å‹
    all_mse = []
    gait_stats = {}
    
    subdirs = ["Normal_free", "Normal_line", "Bag_free", "Bag_line", 
               "Backpack_free", "Backpack_line", "Bag_Phone_free", "Bag_Phone_line"]
    
    for subdir in subdirs:
        subdir_path = dataset_dir / subdir
        if not subdir_path.exists():
            continue
        
        print(f"\n  åˆ†æ {subdir}...")
        subdir_mse = []
        
        # é‡‡æ ·æµ‹è¯•ï¼ˆæ¯ä¸ªç”¨æˆ·å–2å¼ å›¾ï¼‰
        user_dirs = sorted([d for d in subdir_path.iterdir() if d.is_dir()])[:5]  # æµ‹è¯•å‰5ä¸ªç”¨æˆ·
        
        for user_dir in user_dirs:
            images = list(user_dir.glob("*.jpg"))[:2]  # æ¯ä¸ªç”¨æˆ·å–2å¼ 
            
            for img_path in images:
                # åŠ è½½å’Œé¢„å¤„ç†
                pil_img = Image.open(img_path).convert("RGB")
                pil_img = pil_img.resize((256, 256), Image.LANCZOS)
                img_array = np.array(pil_img).astype(np.float32) / 255.0
                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0).to(vae.device)
                
                # è®¡ç®—é‡å»ºè¯¯å·®
                with torch.no_grad():
                    latent = vae.encode_batch(img_tensor)
                    recon = vae.decode_batch(latent)
                    mse = ((img_tensor - recon) ** 2).mean().item()
                    subdir_mse.append(mse)
                    all_mse.append(mse)
        
        if subdir_mse:
            avg_mse = np.mean(subdir_mse)
            std_mse = np.std(subdir_mse)
            gait_stats[subdir] = {"avg": avg_mse, "std": std_mse, "samples": len(subdir_mse)}
            print(f"    MSE: {avg_mse:.5f} Â± {std_mse:.5f} (n={len(subdir_mse)})")
    
    # æ€»ä½“ç»Ÿè®¡
    if all_mse:
        print("\n  ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"    å¹³å‡MSE: {np.mean(all_mse):.5f}")
        print(f"    æ ‡å‡†å·®: {np.std(all_mse):.5f}")
        print(f"    æœ€å°MSE: {np.min(all_mse):.5f}")
        print(f"    æœ€å¤§MSE: {np.max(all_mse):.5f}")
        print(f"    ä¸­ä½æ•°: {np.median(all_mse):.5f}")
        print(f"    æ ·æœ¬æ•°: {len(all_mse)}")
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_path = output_dir / "reconstruction_stats.txt"
        with open(stats_path, 'w') as f:
            f.write("VAEé‡å»ºè´¨é‡ç»Ÿè®¡\n")
            f.write("="*50 + "\n\n")
            f.write("å„æ­¥æ€ç±»å‹ç»Ÿè®¡:\n")
            for gait, stats in gait_stats.items():
                f.write(f"{gait}: MSE={stats['avg']:.5f} Â± {stats['std']:.5f} (n={stats['samples']})\n")
            f.write(f"\næ€»ä½“ç»Ÿè®¡:\n")
            f.write(f"å¹³å‡MSE: {np.mean(all_mse):.5f}\n")
            f.write(f"æ ‡å‡†å·®: {np.std(all_mse):.5f}\n")
            f.write(f"æœ€å°MSE: {np.min(all_mse):.5f}\n")
            f.write(f"æœ€å¤§MSE: {np.max(all_mse):.5f}\n")
            f.write(f"ä¸­ä½æ•°: {np.median(all_mse):.5f}\n")
            f.write(f"æ ·æœ¬æ•°: {len(all_mse)}\n")
        
        print(f"\n  âœ… ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ° {stats_path}")
        
        # ç»“è®º
        avg_mse = np.mean(all_mse)
        if avg_mse < 0.01:
            print("\n  ğŸ¯ ç»“è®º: VAEé‡å»ºè´¨é‡ä¼˜ç§€ï¼MSE < 0.01ï¼Œå®Œå…¨é€‚åˆæ‰©æ•£æ¨¡å‹è®­ç»ƒ")
        elif avg_mse < 0.05:
            print("\n  âœ… ç»“è®º: VAEé‡å»ºè´¨é‡è‰¯å¥½ï¼ŒMSE < 0.05ï¼Œé€‚åˆæ‰©æ•£æ¨¡å‹è®­ç»ƒ")
        else:
            print("\n  âš ï¸ ç»“è®º: VAEé‡å»ºè´¨é‡ä¸€èˆ¬ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´")

if __name__ == "__main__":
    diagnose_vae()
